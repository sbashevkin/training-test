---
title: "Data tidying"
author: "Sam Bashevkin"
date: "11/6/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, warning=FALSE, message=FALSE}
library(dplyr)
library(tidyr)
```

# Read and clean data

```{r}
catch_original <- read.csv(url("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.302.1",
                               method = "libcurl"), 
                           stringsAsFactors = FALSE)
head(catch_original)
```

Remove `All` column and `notesRegCode` column because we don't need them.

```{r}
catch_data <- catch_original %>%
  select(-All, -notesRegCode)

head(catch_data)
```

```{r}
summary(catch_data)
```

## Fix Chinook column

Use `mutate` to fix Chinook column.

```{r}
catch_clean <- catch_data %>% 
  mutate(Chinook=ifelse(Chinook=="I", 1, Chinook)) %>%
  mutate(Chinook = as.numeric(Chinook))

summary(catch_clean)
```

Finding the rows that got turned into `NA`

```{r}
i <- which(is.na(catch_clean$Chinook))
i
```

What was the original value of that `NA`?

```{r}
catch_original[i,]
```

# Reshape data

```{r}
catch_long <- catch_clean %>% 
  pivot_longer(cols = -c(Region, Year), 
               names_to = "Species", 
               values_to = "Catch")

head(catch_long)
```

Practice creating a wide dataframe
```{r}
catch_wide <- catch_long%>%
  pivot_wider(names_from = Year,
              values_from = Catch)

head(catch_wide)
```

`rename` Catch column to `catch_thousands`

```{r}
catch_long <- catch_long %>%
  rename(Catch_thousands = Catch) %>%
  mutate(Catch = Catch_thousands * 1000) %>%
  select(-Catch_thousands)
```

# Summarize data

```{r}
mean_region <- catch_long%>%
  group_by(Region, Species)%>%
  summarise(Catch_mean=mean(Catch), N=n())

mean_region
```

Calculate total catch per species

```{r}
total_species <- catch_long%>%
  group_by(Species)%>%
  summarise(Total_catch=sum(Catch))%>%
  arrange(-Total_catch)

total_species
```

Total catch before 1900

```{r}
total_species_pre_1900 <- catch_long%>%
  filter(Year<1900)%>%
  group_by(Species)%>%
  summarise(Total_catch=sum(Catch))%>%
  arrange(-Total_catch)

total_species_pre_1900
```

# Join to region table

Load `region_defs` data

```{r}
region_defs <- read.csv(url("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.303.1",
                               method = "libcurl"), 
                           stringsAsFactors = FALSE)%>%
  select(code, mgmtArea)

head(region_defs)
```

Join with catch data
```{r}
catch_joined <- left_join(catch_long, region_defs, by=c("Region"="code"))
```

# Separate and unite

```{r}
site_codes <- data.frame(site=c("HAW-100",
                                "HAW-101",
                                "OAH-102",
                                "OAH-103",
                                "MAI-100"),
                         stringsAsFactors = F)
```

separate island and site number using `separate`

```{r}
site_codes_split <- site_codes%>%
  separate(site, into=c("Island", "Site"), sep="-")

site_codes_split
```

Unite
```{r}
site_codes_united <- site_codes_split%>%
  unite("Full_site", Island, Site, sep="_")
  
site_codes_united
```

